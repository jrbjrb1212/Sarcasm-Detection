{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmTsu7GxafnI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "sns.set(font=\"Droid Sans\",font_scale = 1)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_color_codes(\"dark\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1669712298991,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "kFBxJj_WbI-I",
    "outputId": "9ceee5d9-187c-40a3-efcd-cd8338f46ecd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stwrds = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4Li53jjnJ7h"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(\"./Sarcasm_Headlines_Dataset_v2.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4728,
     "status": "ok",
     "timestamp": 1669712380851,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "F7QJkcmNaxFz",
    "outputId": "4051a263-dfee-45ac-8f78-42e10abc231d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13552 sarcastic headlines and 14951 non-sarcastic headlines\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate headlines\n",
    "data=data.drop(data[data['headline'].duplicated()].index,axis=0)\n",
    "sarc_cnt = len(data.query('is_sarcastic==1'))\n",
    "non_sarc_cnt = len(data.query('is_sarcastic==0'))\n",
    "\n",
    "# Summary of sarcastic lines\n",
    "print(f'There are {sarc_cnt} sarcastic headlines and {non_sarc_cnt} non-sarcastic headlines')\n",
    "# import stopwords from nltk\n",
    "stwrds = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "# method to clean a given headline by lowercasing the string, removing spaces, and removing stopwords\n",
    "def clean_headlines(headline):\n",
    "    headline = headline.lower()\n",
    "    headline_split = headline.split()\n",
    "    cleaned_headline = []\n",
    "    for word in headline_split:\n",
    "        if word not in stwrds and word not in string.punctuation:\n",
    "            cleaned_headline.append(ps.stem(word))\n",
    "    cleaned_line = \" \".join(cleaned_headline)\n",
    "    return cleaned_line\n",
    "data['cleaned'] = data['headline'].apply(clean_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnsOcSIybDHb"
   },
   "outputs": [],
   "source": [
    "labels=data.is_sarcastic \n",
    "features=data.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx340Lrvc86q"
   },
   "outputs": [],
   "source": [
    "fet_train,fet_test, lab_train,lab_test = train_test_split(features,labels ,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1669712385890,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "gkVBTH2jcy9s",
    "outputId": "13ab462c-90f3-4549-ea04-a855b052c19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21962\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(fet_train)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "print(vocab_size)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(fet_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(fet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPhMY1QHeBx-"
   },
   "outputs": [],
   "source": [
    "maxlen=max([len(i) for i in train_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1669712389254,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "lShRyBgwhMEz",
    "outputId": "745824ae-ac28-414c-c856-455bc77ab6b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCpsUvIulHIh"
   },
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=maxlen,  padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=maxlen,  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHpCILI2bYzf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Dropout, Flatten, Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GodYoPyYbusZ"
   },
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Embedding(input_dim=vocab_size+1,output_dim=100,input_length=maxlen))\n",
    "model.add(Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add (Dense(64,activation='relu'))\n",
    "model.add (Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "#Compiling the model, loss: categorical crossentropy, it is the most popular for these kind of problems,\n",
    "#optimizer: adam, a faster variant of the stochastic gradient method\n",
    "#metrics: accuracy (We want to know the accuracy after each epoch.)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1669712400212,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "eqaupgmPcN9Y",
    "outputId": "743a0c84-53d9-4f87-cd3c-5096e85504c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 107, 100)          2196300   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              234496    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,447,309\n",
      "Trainable params: 2,447,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# early_stopping=EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "#We do not want to store the weights of the model after the last epoch, we want the weights of the best model!\n",
    "#We will store those weights in a file weights.hdf5\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "#We call the fit method with 100 epochs, 128 batch_size, and 0.2 validation split. \n",
    "#We have to specify which callbacks or 'plugins' we want to use.\n",
    "# network_history = model.fit(fet_train, lab_train)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68801,
     "status": "ok",
     "timestamp": 1669712471169,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "Fpb_tjlGeRo6",
    "outputId": "20127374-8f3f-45bd-92a3-b19413722799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "713/713 - 249s - loss: 0.4809 - accuracy: 0.7562 - val_loss: 0.4080 - val_accuracy: 0.8099 - 249s/epoch - 349ms/step\n",
      "Epoch 2/5\n",
      "713/713 - 243s - loss: 0.2397 - accuracy: 0.9007 - val_loss: 0.4668 - val_accuracy: 0.7935 - 243s/epoch - 340ms/step\n",
      "Epoch 3/5\n",
      "713/713 - 244s - loss: 0.1260 - accuracy: 0.9542 - val_loss: 0.6369 - val_accuracy: 0.7811 - 244s/epoch - 343ms/step\n",
      "Epoch 4/5\n",
      "713/713 - 243s - loss: 0.0737 - accuracy: 0.9729 - val_loss: 0.7235 - val_accuracy: 0.7820 - 243s/epoch - 340ms/step\n",
      "Epoch 5/5\n",
      "713/713 - 247s - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.9027 - val_accuracy: 0.7755 - 247s/epoch - 346ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_padded, np.array(lab_train),validation_data = (test_padded,np.array(lab_test)) , epochs = 5 , verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1669712682836,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "VM9MbAfDkrX2",
    "outputId": "f3c2c47d-ec37-45a9-c3a5-9b3a1af5047b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWnc9-DAoJu4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669713233865,
     "user": {
      "displayName": "Yusuf Ismail",
      "userId": "01109268713179766420"
     },
     "user_tz": -60
    },
    "id": "ygtr17r7qAbm",
    "outputId": "e676357c-1179-4a00-a7d6-43e43f656b20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvVf93oSpXa7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP8sGCDh4liXoHU3KUB1DEE",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
