{"cells":[{"cell_type":"code","execution_count":null,"id":"74a30d4b","metadata":{"id":"74a30d4b"},"outputs":[],"source":["import tensorflow"]},{"cell_type":"code","execution_count":null,"id":"bda5c676","metadata":{"id":"bda5c676"},"outputs":[],"source":["import tensorflow.keras as keras"]},{"cell_type":"code","execution_count":null,"id":"fb3dffb7","metadata":{"id":"fb3dffb7"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import nltk\n","import tensorflow as tf\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":null,"id":"bca784f4","metadata":{"id":"bca784f4"},"outputs":[],"source":["# Use pd.read_json(\"../Sarcasm_Headlines_Dataset_v2.json\",lines=True) if not in colab\n","data = pd.read_json(\"./Sarcasm_Headlines_Dataset_v2.json\",lines=True)"]},{"cell_type":"code","execution_count":null,"id":"a6459d94","metadata":{"id":"a6459d94"},"outputs":[],"source":["# remove duplicate headlines\n","data=data.drop(data[data['headline'].duplicated()].index,axis=0)"]},{"cell_type":"code","execution_count":null,"id":"39654b99","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39654b99","outputId":"6dd9da44-cba3-4a6d-b330-7b358429bc99","scrolled":true,"executionInfo":{"status":"ok","timestamp":1670813415567,"user_tz":-60,"elapsed":5,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 13552 sarcastic headlines and 14951 non-sarcastic headlines\n"]}],"source":["sarc_cnt = len(data.query('is_sarcastic==1'))\n","non_sarc_cnt = len(data.query('is_sarcastic==0'))\n","\n","# Summary of sarcastic lines\n","print(f'There are {sarc_cnt} sarcastic headlines and {non_sarc_cnt} non-sarcastic headlines')"]},{"cell_type":"markdown","id":"fe773c72","metadata":{"id":"fe773c72"},"source":["---"]},{"cell_type":"markdown","id":"85e473f3","metadata":{"id":"85e473f3"},"source":["## Part 2: Data Processing/Cleaning"]},{"cell_type":"code","execution_count":null,"id":"ea4O6NMYh7rX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea4O6NMYh7rX","outputId":"7ce7d9d5-eeb7-4d8f-def3-fc290227e3a5","scrolled":true,"executionInfo":{"status":"ok","timestamp":1670798242323,"user_tz":-60,"elapsed":4,"user":{"displayName":"Yusuf Ismail","userId":"01109268713179766420"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"id":"b61911e7","metadata":{"id":"b61911e7"},"outputs":[],"source":["stwrds = set(stopwords.words('english'))\n"]},{"cell_type":"code","execution_count":null,"id":"b8b94e27","metadata":{"id":"b8b94e27"},"outputs":[],"source":["# # method to clean a given headline by lowercasing the string, removing spaces, and removing stopwords\n","# def clean_headlines(headline):\n","#     headline = headline.lower()\n","#     headline_split = headline.split()\n","#     cleaned_headline = []\n","#     for word in headline_split:\n","#         if word not in stwrds:\n","#             cleaned_headline.append(word)\n","    \n","#     cleaned_line = \" \".join(cleaned_headline)\n","#     return cleaned_line"]},{"cell_type":"code","execution_count":null,"id":"bf55ecb0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf55ecb0","outputId":"f4abedc0-9e2d-4ba4-e22c-eeb8e51a6585"},"outputs":[{"data":{"text/plain":["0        thirtysomething scientists unveil doomsday clo...\n","1        dem rep. totally nails congress falling short ...\n","2             eat veggies: 9 deliciously different recipes\n","3             inclement weather prevents liar getting work\n","4        mother comes pretty close using word 'streamin...\n","                               ...                        \n","28614               jews celebrate rosh hashasha something\n","28615    internal affairs investigator disappointed con...\n","28616    beautiful acceptance speech week came queer ko...\n","28617    mars probe destroyed orbiting spielberg-gates ...\n","28618                              dad clarifies food stop\n","Name: headline, Length: 28503, dtype: object"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["# # applies function to all entries\n","# data['headline'].apply(clean_headlines)"]},{"cell_type":"code","execution_count":null,"id":"01117f3b","metadata":{"id":"01117f3b"},"outputs":[],"source":["# # train-test split\n","# headline_target = data['is_sarcastic']\n","# headline_attributes = data['headline']\n","# attribute_train, attribute_test, labels_train, labels_test = train_test_split(headline_attributes, headline_target, test_size=0.30)\n"]},{"cell_type":"code","execution_count":null,"id":"22762ee6","metadata":{"id":"22762ee6"},"outputs":[],"source":["# # form dataframes for training and test sets\n","# att_train = pd.DataFrame(attribute_train)\n","# label_train = pd.DataFrame(labels_train)\n","# att_test = pd.DataFrame(attribute_test)\n","# label_test = pd.DataFrame(labels_test)\n","\n","# training_set = label_train.join(att_train)\n","# test_set = label_test.join(att_test)"]},{"cell_type":"code","execution_count":null,"id":"597bf06e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"597bf06e","outputId":"24f515e9-21e8-44f1-a408-e6683e041825"},"outputs":[{"name":"stdout","output_type":"stream","text":["38234 unqiue words in the headline data\n"]}],"source":["# # determines amount of unqiue words in our data\n","# # this takes forever because set operations are slow\n","\n","# unqiue_words = set()\n","# for headline in headline_attributes:\n","#     unqiue_words = unqiue_words.union(set(headline.split()))\n","\n","# print(f'{len(unqiue_words)} unqiue words in the headline data')"]},{"cell_type":"code","execution_count":null,"id":"b395b607","metadata":{"id":"b395b607"},"outputs":[],"source":["data['tokenized_text'] = data.headline.apply(tokenizer.tokenize)"]},{"cell_type":"code","execution_count":null,"id":"2baf4400","metadata":{"scrolled":true,"id":"2baf4400"},"outputs":[],"source":["data['indexed_tokens'] = data.tokenized_text.apply(tokenizer.convert_tokens_to_ids)"]},{"cell_type":"code","execution_count":null,"id":"69326d41","metadata":{"scrolled":true,"id":"69326d41","outputId":"e5e1bc84-46c0-47dd-f24b-58a133487252"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>is_sarcastic</th>\n","      <th>headline</th>\n","      <th>article_link</th>\n","      <th>tokenized_text</th>\n","      <th>indexed_tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>thirtysomething scientists unveil doomsday clo...</td>\n","      <td>https://www.theonion.com/thirtysomething-scien...</td>\n","      <td>[thirty, ##some, ##thing, scientists, un, ##ve...</td>\n","      <td>[4228, 14045, 20744, 6529, 4895, 3726, 4014, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>dem rep. totally nails why congress is falling...</td>\n","      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n","      <td>[dem, rep, ., totally, nails, why, congress, i...</td>\n","      <td>[17183, 16360, 1012, 6135, 10063, 2339, 3519, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>eat your veggies: 9 deliciously different recipes</td>\n","      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n","      <td>[eat, your, ve, ##gg, ##ies, :, 9, delicious, ...</td>\n","      <td>[4521, 2115, 2310, 13871, 3111, 1024, 1023, 12...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>inclement weather prevents liar from getting t...</td>\n","      <td>https://local.theonion.com/inclement-weather-p...</td>\n","      <td>[inc, ##lem, ##ent, weather, prevents, liar, f...</td>\n","      <td>[4297, 16930, 4765, 4633, 16263, 16374, 2013, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>mother comes pretty close to using word 'strea...</td>\n","      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n","      <td>[mother, comes, pretty, close, to, using, word...</td>\n","      <td>[2388, 3310, 3492, 2485, 2000, 2478, 2773, 100...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   is_sarcastic                                           headline  \\\n","0             1  thirtysomething scientists unveil doomsday clo...   \n","1             0  dem rep. totally nails why congress is falling...   \n","2             0  eat your veggies: 9 deliciously different recipes   \n","3             1  inclement weather prevents liar from getting t...   \n","4             1  mother comes pretty close to using word 'strea...   \n","\n","                                        article_link  \\\n","0  https://www.theonion.com/thirtysomething-scien...   \n","1  https://www.huffingtonpost.com/entry/donna-edw...   \n","2  https://www.huffingtonpost.com/entry/eat-your-...   \n","3  https://local.theonion.com/inclement-weather-p...   \n","4  https://www.theonion.com/mother-comes-pretty-c...   \n","\n","                                      tokenized_text  \\\n","0  [thirty, ##some, ##thing, scientists, un, ##ve...   \n","1  [dem, rep, ., totally, nails, why, congress, i...   \n","2  [eat, your, ve, ##gg, ##ies, :, 9, delicious, ...   \n","3  [inc, ##lem, ##ent, weather, prevents, liar, f...   \n","4  [mother, comes, pretty, close, to, using, word...   \n","\n","                                      indexed_tokens  \n","0  [4228, 14045, 20744, 6529, 4895, 3726, 4014, 1...  \n","1  [17183, 16360, 1012, 6135, 10063, 2339, 3519, ...  \n","2  [4521, 2115, 2310, 13871, 3111, 1024, 1023, 12...  \n","3  [4297, 16930, 4765, 4633, 16263, 16374, 2013, ...  \n","4  [2388, 3310, 3492, 2485, 2000, 2478, 2773, 100...  "]},"execution_count":128,"metadata":{},"output_type":"execute_result"}],"source":["data.head(5)"]},{"cell_type":"code","execution_count":null,"id":"af356c61","metadata":{"scrolled":true,"id":"af356c61","outputId":"92cccbd0-82ae-4680-fb86-e0386ba88b2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["thirty        4,228\n","##some       14,045\n","##thing      20,744\n","scientists    6,529\n","un            4,895\n","##ve          3,726\n","##il          4,014\n","doom         12,677\n","##sd         16,150\n","##ay          4,710\n","clock         5,119\n","of            1,997\n","hair          2,606\n","loss          3,279\n"]},{"name":"stderr","output_type":"stream","text":["The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n"]}],"source":["for tup in zip(data.tokenized_text[:1], data.indexed_tokens[:1]):\n","    for tup2 in zip(tup[0],tup[1]):\n","        print('{:<12} {:>6,}'.format(tup2[0], tup2[1]))\n"]},{"cell_type":"code","execution_count":null,"id":"9bb0f0f6","metadata":{"id":"9bb0f0f6"},"outputs":[],"source":["segments_ids = [1] * len(data.tokenized_text)"]},{"cell_type":"code","execution_count":null,"id":"ae0792c0","metadata":{"id":"ae0792c0"},"outputs":[],"source":["data['tokens_tensor'] = data.indexed_tokens.apply(torch.tensor)\n","data['segments_tensors'] = torch.tensor([1]* len(data.tokenized_text))"]},{"cell_type":"code","execution_count":null,"id":"dba265c1","metadata":{"id":"dba265c1","outputId":"587bf179-9d19-4ddc-84a5-c36edddfd051"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>is_sarcastic</th>\n","      <th>headline</th>\n","      <th>article_link</th>\n","      <th>tokenized_text</th>\n","      <th>indexed_tokens</th>\n","      <th>tokens_tensor</th>\n","      <th>segments_tensors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>thirtysomething scientists unveil doomsday clo...</td>\n","      <td>https://www.theonion.com/thirtysomething-scien...</td>\n","      <td>[thirty, ##some, ##thing, scientists, un, ##ve...</td>\n","      <td>[4228, 14045, 20744, 6529, 4895, 3726, 4014, 1...</td>\n","      <td>[tensor(4228), tensor(14045), tensor(20744), t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>dem rep. totally nails why congress is falling...</td>\n","      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n","      <td>[dem, rep, ., totally, nails, why, congress, i...</td>\n","      <td>[17183, 16360, 1012, 6135, 10063, 2339, 3519, ...</td>\n","      <td>[tensor(17183), tensor(16360), tensor(1012), t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>eat your veggies: 9 deliciously different recipes</td>\n","      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n","      <td>[eat, your, ve, ##gg, ##ies, :, 9, delicious, ...</td>\n","      <td>[4521, 2115, 2310, 13871, 3111, 1024, 1023, 12...</td>\n","      <td>[tensor(4521), tensor(2115), tensor(2310), ten...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>inclement weather prevents liar from getting t...</td>\n","      <td>https://local.theonion.com/inclement-weather-p...</td>\n","      <td>[inc, ##lem, ##ent, weather, prevents, liar, f...</td>\n","      <td>[4297, 16930, 4765, 4633, 16263, 16374, 2013, ...</td>\n","      <td>[tensor(4297), tensor(16930), tensor(4765), te...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>mother comes pretty close to using word 'strea...</td>\n","      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n","      <td>[mother, comes, pretty, close, to, using, word...</td>\n","      <td>[2388, 3310, 3492, 2485, 2000, 2478, 2773, 100...</td>\n","      <td>[tensor(2388), tensor(3310), tensor(3492), ten...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   is_sarcastic                                           headline  \\\n","0             1  thirtysomething scientists unveil doomsday clo...   \n","1             0  dem rep. totally nails why congress is falling...   \n","2             0  eat your veggies: 9 deliciously different recipes   \n","3             1  inclement weather prevents liar from getting t...   \n","4             1  mother comes pretty close to using word 'strea...   \n","\n","                                        article_link  \\\n","0  https://www.theonion.com/thirtysomething-scien...   \n","1  https://www.huffingtonpost.com/entry/donna-edw...   \n","2  https://www.huffingtonpost.com/entry/eat-your-...   \n","3  https://local.theonion.com/inclement-weather-p...   \n","4  https://www.theonion.com/mother-comes-pretty-c...   \n","\n","                                      tokenized_text  \\\n","0  [thirty, ##some, ##thing, scientists, un, ##ve...   \n","1  [dem, rep, ., totally, nails, why, congress, i...   \n","2  [eat, your, ve, ##gg, ##ies, :, 9, delicious, ...   \n","3  [inc, ##lem, ##ent, weather, prevents, liar, f...   \n","4  [mother, comes, pretty, close, to, using, word...   \n","\n","                                      indexed_tokens  \\\n","0  [4228, 14045, 20744, 6529, 4895, 3726, 4014, 1...   \n","1  [17183, 16360, 1012, 6135, 10063, 2339, 3519, ...   \n","2  [4521, 2115, 2310, 13871, 3111, 1024, 1023, 12...   \n","3  [4297, 16930, 4765, 4633, 16263, 16374, 2013, ...   \n","4  [2388, 3310, 3492, 2485, 2000, 2478, 2773, 100...   \n","\n","                                       tokens_tensor  segments_tensors  \n","0  [tensor(4228), tensor(14045), tensor(20744), t...                 1  \n","1  [tensor(17183), tensor(16360), tensor(1012), t...                 1  \n","2  [tensor(4521), tensor(2115), tensor(2310), ten...                 1  \n","3  [tensor(4297), tensor(16930), tensor(4765), te...                 1  \n","4  [tensor(2388), tensor(3310), tensor(3492), ten...                 1  "]},"execution_count":175,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"id":"5bf78385","metadata":{"collapsed":true,"id":"5bf78385","outputId":"666049bb-15f1-4d10-b349-e0602382db18"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["model = BertModel.from_pretrained('bert-base-uncased',\n","                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n","                                  )\n","\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n","model.eval()\n"]},{"cell_type":"markdown","id":"25cb5e57","metadata":{"id":"25cb5e57"},"source":["# new stuff"]},{"cell_type":"code","execution_count":null,"id":"189a03c3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"189a03c3","executionInfo":{"status":"ok","timestamp":1670813435761,"user_tz":-60,"elapsed":14722,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"42c34bc5-6f50-48d9-8e08-93ebc3541672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 30.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 77.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 55.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install transformers\n","from transformers import TFBertModel, BertTokenizer\n"]},{"cell_type":"markdown","id":"2bace4a4","metadata":{"id":"2bace4a4"},"source":["# Hopefully that would work"]},{"cell_type":"code","execution_count":null,"id":"0dc166af","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["7f0d01b0ff3d47bcbfb3f989c560ec2e","f08a8b80d9074fa5b92df28b6b1378c5","c0083c855d4a4e64878ff403c752370c","521e61a6e70549c0b5c2158dac6abe2a","bc3be1322fd24c6a8b9cb582def7721b","01eb5c6469874f9babfd8ef7ab3091be","c66141cb788f4a928422302431856c35","8470d042ec2d429d9ef52e6ea07db222","084f849ae862426099fcfdcd882c1e23","6cae8036ac1245b48adfa2624b72de34","4efc691372cd44c4b9e1cd7a46842723","521ffa23dea940808244fab46a24c6e5","488e4fd5da2648868989b3d7a0d26085","e5320a0fd40c4544bdcf218915be922a","8fcd4b61c31c4000879fccf2eb353a5d","5eafff19aae44e0cabaf86820a09d247","5cc61425a81843928137581fb48ab731","77383d5d3e9b4e5ea3b12df059b7b0d5","557da984cab744e6873bc4d0610927e8","01baf34aaaa7428489f5d1fa2ab7b2c7","754a88b2d4d94d4eae5f19673a3519c4","6aaaea093c214dbc99bc8ace61b4a5f1","d3843ba28a494e2ab47abbdae600fc09","d143e2a966ab4ac089d5f62e7f0d6500","cd6d0e987845400798c4a2baa04ad535","52e1adabc57b433db4feabc466046c8b","74c6ce947c1e474e8e184a1e25a16f69","077b05b03d0b4f99b1dd44f8cd114cd7","a655b3ebd6374483b62b3e19e702c436","13acf7dc59f44ec3b1f4697d4c27c0a3","9aee2687f6a2496ab44c39998133ad87","48fc101ce6fc4ac2b4c5a2b29c91f9e3","657a3e5bd7154fbcbeedacad2b33e3fc"]},"id":"0dc166af","executionInfo":{"status":"ok","timestamp":1670813441639,"user_tz":-60,"elapsed":879,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"e4e34d09-cfd4-4372-c6ee-f5433ce54e2e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0d01b0ff3d47bcbfb3f989c560ec2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521ffa23dea940808244fab46a24c6e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3843ba28a494e2ab47abbdae600fc09"}},"metadata":{}}],"source":["labels = data.is_sarcastic.values\n","sentences = data.headline.values\n","PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME,do_lower_case = True)"]},{"cell_type":"code","execution_count":null,"id":"181dc230","metadata":{"id":"181dc230"},"outputs":[],"source":["def encoder(sentences):\n","    ids = []\n","    for sentence in sentences:\n","        encoding = tokenizer.encode_plus(\n","        sentence,\n","        max_length=16,\n","        truncation = True,\n","        add_special_tokens=True,\n","        return_token_type_ids=False,\n","        padding=\"max_length\",\n","        return_attention_mask=False)\n","        ids.append(encoding['input_ids'])\n","    return ids\n","\n","train_sents,test_sents, train_labels, test_labels  = train_test_split(sentences,labels,test_size=0.15)\n","train_ids = encoder(train_sents)\n","test_ids = encoder(test_sents) "]},{"cell_type":"code","execution_count":null,"id":"700200d7","metadata":{"id":"700200d7"},"outputs":[],"source":["train_ids = tf.convert_to_tensor(train_ids)\n","test_ids = tf.convert_to_tensor(test_ids)\n","test_labels = tf.convert_to_tensor(test_labels)\n","train_labels = tf.convert_to_tensor(train_labels)"]},{"cell_type":"code","execution_count":null,"id":"80058362","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["bd2947fdc6814351808d95c0cea6c757","650c87a5bbe84e1593fae5b4d4f6413e","cd02af6a01764713b75873369667954a","d73b59eae53f416ea30394a6c2d7e2b4","0337bd2fec24404aba8f4319248052aa","25c0178fe65449a5ad705cf250c89bf0","66697ae1026b4161a9ff182c76d4567c","b848a5186df04d6ea605d38835ddf285","ffc6725f07364079be53fa2b0cc27d80","263e6fcf9a1340a1868e399df3fb2189","224f1386a4a1404ea4f5dba62cf90b63"]},"id":"80058362","executionInfo":{"status":"ok","timestamp":1670813492994,"user_tz":-60,"elapsed":18508,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"73152407-77ab-4077-f8b7-677c8ad922be"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2947fdc6814351808d95c0cea6c757"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n","input_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")  \n","embedding = bert_encoder([input_word_ids])\n","dense = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(embedding[0])\n","dense = tf.keras.layers.Dense(128, activation='relu')(dense)\n","dense = tf.keras.layers.Dropout(0.2)(dense)   \n","output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)    \n","checkpointer=ModelCheckpoint(filepath='LSTM_model.hdf5', save_best_only=True, verbose=2)\n","\n","model = tf.keras.Model(inputs=[input_word_ids], outputs=output)  \n"]},{"cell_type":"code","execution_count":null,"id":"a08d4a6a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a08d4a6a","executionInfo":{"status":"ok","timestamp":1670813492995,"user_tz":-60,"elapsed":24,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"015feba5-d563-4c2c-979e-feae49678c1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_word_ids (InputLayer)  [(None, 16)]             0         \n","                                                                 \n"," tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  109482240\n","                             lingAndCrossAttentions(l            \n","                             ast_hidden_state=(None,             \n","                             16, 768),                           \n","                              pooler_output=(None, 76            \n","                             8),                                 \n","                              past_key_values=None, h            \n","                             idden_states=None, atten            \n","                             tions=None, cross_attent            \n","                             ions=None)                          \n","                                                                 \n"," lambda (Lambda)             (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               98432     \n","                                                                 \n"," dropout_37 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 109,580,801\n","Trainable params: 109,580,801\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.compile(tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"4cd64a88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cd64a88","executionInfo":{"status":"ok","timestamp":1670813780098,"user_tz":-60,"elapsed":279811,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"3420390f-fe49-4f5a-f608-198bb4d82b0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["95/95 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8038\n","Epoch 1: val_loss improved from inf to 0.27296, saving model to LSTM_model.hdf5\n","95/95 [==============================] - 103s 895ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.2730 - val_accuracy: 0.8845\n","Epoch 2/3\n","95/95 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.8976\n","Epoch 2: val_loss improved from 0.27296 to 0.25603, saving model to LSTM_model.hdf5\n","95/95 [==============================] - 85s 892ms/step - loss: 0.2491 - accuracy: 0.8976 - val_loss: 0.2560 - val_accuracy: 0.8920\n","Epoch 3/3\n","95/95 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9254\n","Epoch 3: val_loss improved from 0.25603 to 0.20963, saving model to LSTM_model.hdf5\n","95/95 [==============================] - 84s 884ms/step - loss: 0.1917 - accuracy: 0.9254 - val_loss: 0.2096 - val_accuracy: 0.9167\n"]}],"source":["history = model.fit(x = train_ids, y = train_labels, epochs = 3, verbose = 1, batch_size = 256, validation_data = (test_ids, test_labels), callbacks=[checkpointer])"]},{"cell_type":"code","execution_count":null,"id":"51335b74","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":541},"id":"51335b74","executionInfo":{"status":"ok","timestamp":1670813790269,"user_tz":-60,"elapsed":514,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"bf4d6d12-746a-47c0-d247-ce08cab0cd81"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')\n","plot_graphs(history, 'loss')"]},{"cell_type":"code","source":["from keras.models import load_model\n","model = load_model('model.h5')"],"metadata":{"id":"m6KHHIknWxsr"},"id":"m6KHHIknWxsr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model(test_ids[0:10])"],"metadata":{"id":"_LWHwzuSEd93"},"id":"_LWHwzuSEd93","execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(x = train_ids, y = train_labels, epochs = 3, verbose = 1, batch_size = 32, validation_data = (test_ids, test_labels), callbacks=[checkpointer])"],"metadata":{"id":"5YBtGWJJ_vgX"},"id":"5YBtGWJJ_vgX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install shap"],"metadata":{"id":"LNemQO7ZQ53v"},"id":"LNemQO7ZQ53v","execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = test_sents[0]\n","encoding = tokenizer.encode_plus(\n","            x,\n","            max_length=16,\n","            truncation = True,\n","            add_special_tokens=True,\n","            return_token_type_ids=False,\n","            padding=\"max_length\",\n","            return_attention_mask=False)\n","asinput = encoding.input_ids\n","outputs = model(tf.convert_to_tensor([asinput]))[0]\n","print(outputs)\n","np.log(outputs[0]/(1-outputs[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgee81HjVAB4","executionInfo":{"status":"ok","timestamp":1670814993062,"user_tz":-60,"elapsed":1471,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"8602c234-4fc2-430b-be1e-012c469448c0"},"id":"cgee81HjVAB4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([0.994228], shape=(1,), dtype=float32)\n"]},{"output_type":"execute_result","data":{"text/plain":["5.1489487"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["import shap\n","import transformers\n","tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","def f(x):\n","    x = test_sents[0]\n","    encoding = tokenizer.encode_plus(\n","                x,\n","                max_length=16,\n","                truncation = True,\n","                add_special_tokens=True,\n","                return_token_type_ids=False,\n","                padding=\"max_length\",\n","                return_attention_mask=False)\n","    asinput = encoding.input_ids\n","    outputs = model(tf.convert_to_tensor([asinput]))[0]\n","    val = np.log(outputs[0]/(1-outputs[0]))    \n","    return val\n","\n","explainer = shap.Explainer(f, tokenizer)\n","shap_values = explainer(test_sents[:1], fixed_context=1)\n","\n","# shap_values = explainer(test_sents[0:19])\n","\n","# for i in range (10):\n","#     shap.plots.text(shap_values[i])\n"],"metadata":{"id":"XMIg5l2A8TIE","executionInfo":{"status":"error","timestamp":1670815173608,"user_tz":-60,"elapsed":648,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"0476d1cb-d06b-4416-f916-99d44587583f"},"id":"XMIg5l2A8TIE","execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-b3495e017a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# shap_values = explainer(test_sents[0:19])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\" Explain the output of the model on the given arguments.\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# if not fixed background or no base value assigned then compute base value for a row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fixed_background\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# the zero index param tells the masked model what the baseline is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_masked_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_assert_output_input_match\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;34mf\"The model produced {len(outputs)} output rows when given {len(inputs[0])} input rows! Check the implementation of the model you provided for errors.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: len() of unsized object"]}]},{"cell_type":"code","source":["train_sents[0:5]"],"metadata":{"id":"uYWZMrBebZre"},"id":"uYWZMrBebZre","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Fzrx8YpTpXW","executionInfo":{"status":"ok","timestamp":1670814551727,"user_tz":-60,"elapsed":9964,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"2d71c0b4-2675-41d9-fd15-b2fb4c34b77f"},"id":"4Fzrx8YpTpXW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlp\n","  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 23.2 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from nlp) (0.3.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from nlp) (3.8.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from nlp) (2.23.0)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from nlp) (9.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nlp) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nlp) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 64.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from nlp) (4.64.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (2022.9.24)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nlp) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nlp) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n","Installing collected packages: xxhash, nlp\n","Successfully installed nlp-0.4.0 xxhash-3.1.0\n"]}]},{"cell_type":"code","source":["import shap\n","import transformers\n","import nlp\n","import torch\n","import numpy as np\n","import scipy as sp\n","\n","# load a BERT sentiment analysis model\n","tokenizer2 = BertTokenizer\n","model2 = transformers.DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",").cuda()\n","\n","# define a prediction function\n","def f(x):\n","    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=500, truncation=True) for v in x]).cuda()\n","    outputs = model2(tv)[0].detach().cpu().numpy()\n","    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n","    val = sp.special.logit(scores[:,1]) # use one vs rest logit units\n","    x = test_sents[0]\n","    encoding = tokenizer.encode_plus(\n","                x,\n","                max_length=16,\n","                truncation = True,\n","                add_special_tokens=True,\n","                return_token_type_ids=False,\n","                padding=\"max_length\",\n","                return_attention_mask=False)\n","    asinput = encoding.input_ids\n","    outputs = model(tf.convert_to_tensor([asinput]))[0]\n","    print(val)\n","    return val\n","\n","# build an explainer using a token masker\n","explainer2 = shap.Explainer(f, tokenizer)\n","\n","# explain the model's predictions on IMDB reviews\n","imdb_train = nlp.load_dataset(\"imdb\")[\"train\"]"],"metadata":{"id":"ecA6wYLed8gG"},"id":"ecA6wYLed8gG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap_values2 = explainer2(test_sents[:1], fixed_context=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"CZ4-yBjsTnnI","executionInfo":{"status":"error","timestamp":1670815712043,"user_tz":-60,"elapsed":279,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"ebd47aad-ea38-4f81-ec19-3f3adc6835f2"},"id":"CZ4-yBjsTnnI","execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-1d672f5aa16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\" Explain the output of the model on the given arguments.\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# if not fixed background or no base value assigned then compute base value for a row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fixed_background\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# the zero index param tells the masked model what the baseline is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_masked_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/shap/models/_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tensor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-93-063de4f995fe>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use one vs rest logit units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasLtMatmul( ltHandle, computeDesc.descriptor(), &alpha_val, mat1_ptr, Adesc.descriptor(), mat2_ptr, Bdesc.descriptor(), &beta_val, result_ptr, Cdesc.descriptor(), result_ptr, Cdesc.descriptor(), &heuristicResult.algo, workspace.data_ptr(), workspaceSize, at::cuda::getCurrentCUDAStream())`"]}]},{"cell_type":"code","source":["shap.plots.text(shap_values2[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118},"id":"74HF_sdyT-sV","executionInfo":{"status":"ok","timestamp":1670815273116,"user_tz":-60,"elapsed":246,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"6fc09afa-5883-4625-87a2-e0b247dc179f"},"id":"74HF_sdyT-sV","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<svg width=\"100%\" height=\"80px\"><line x1=\"0\" y1=\"33\" x2=\"100%\" y2=\"33\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><line x1=\"42.77499745750257%\" y1=\"33\" x2=\"42.77499745750257%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"42.77499745750257%\" y=\"27\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-3.1</text><line x1=\"24.858660659791934%\" y1=\"33\" x2=\"24.858660659791934%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"24.858660659791934%\" y=\"27\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-3.2</text><line x1=\"60.6913342552132%\" y1=\"33\" x2=\"60.6913342552132%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"60.6913342552132%\" y=\"27\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-3</text><line x1=\"78.60767105292382%\" y1=\"33\" x2=\"78.60767105292382%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"78.60767105292382%\" y=\"27\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-2.9</text><line x1=\"89.26599110368704%\" y1=\"33\" x2=\"89.26599110368704%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"89.26599110368704%\" y=\"27\" font-size=\"13px\" style=\"stroke:#ffffff;stroke-width:8px;\" fill=\"rgb(255,255,255)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-2.84051</text><text x=\"89.26599110368704%\" y=\"27\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-2.84051</text><text x=\"89.26599110368704%\" y=\"10\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">base value</text><line x1=\"10.734007104679272%\" y1=\"33\" x2=\"10.734007104679272%\" y2=\"37\" style=\"stroke:rgb(150,150,150);stroke-width:1\" /><text x=\"10.734007104679272%\" y=\"27\" font-size=\"13px\" style=\"stroke:#ffffff;stroke-width:8px;\" font-weight=\"bold\" fill=\"rgb(255,255,255)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-3.27884</text><text x=\"10.734007104679272%\" y=\"27\" font-size=\"13px\" font-weight=\"bold\" fill=\"rgb(0,0,0)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">-3.27884</text><text x=\"10.734007104679272%\" y=\"10\" font-size=\"12px\" fill=\"rgb(120,120,120)\" dominant-baseline=\"bottom\" text-anchor=\"middle\">f<tspan baseline-shift=\"sub\" font-size=\"8px\"></tspan>(inputs)</text><rect x=\"9.330940096121948%\" width=\"1.4030670085573238%\" y=\"40\" height=\"18\" style=\"fill:rgb(255.0, 0.0, 81.08083606031792); stroke-width:0; stroke:rgb(0,0,0)\" /><line x1=\"9.455803940044104%\" x2=\"10.734007104679272%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_4\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2; opacity: 0\"/><text x=\"10.094905522361689%\" y=\"71\" font-size=\"12px\" id=\"_fs_gffxajtqekncpkywuikj_ind_4\" fill=\"rgb(255.0, 0.0, 81.08083606031792)\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">0.007</text><svg x=\"9.455803940044104%\" y=\"40\" height=\"20\" width=\"1.2782031646351673%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">s</text>  </svg></svg><line x1=\"9.330940096121948%\" x2=\"9.455803940044104%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_9\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2; opacity: 0\"/><text x=\"9.393372018083026%\" y=\"71\" font-size=\"12px\" id=\"_fs_gffxajtqekncpkywuikj_ind_9\" fill=\"rgb(255.0, 0.0, 81.08083606031792)\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">0.001</text><svg x=\"9.330940096121948%\" y=\"40\" height=\"20\" width=\"0.12486384392215655%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">s</text>  </svg></svg><g transform=\"translate(0,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(4,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(6,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(-6,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"9.455803940044104%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255.0, 0.0, 81.08083606031792);stroke-width:2\" />  </svg></g><rect transform=\"translate(-8,0)\" x=\"10.734007104679272%\" y=\"40\" width=\"8\" height=\"18\" style=\"fill:rgb(255.0, 0.0, 81.08083606031792)\"/><g transform=\"translate(-11.5,0)\">  <svg x=\"9.330940096121948%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 10 -9 l 6 18 L 10 25 L 0 25 L 0 -9\" fill=\"#ffffff\" style=\"stroke:rgb(255,255,255);stroke-width:2\" />  </svg></g><g transform=\"translate(-1.5,0)\">  <svg x=\"10.734007104679272%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 0 -9 l 6 18 L 0 25\" fill=\"none\" style=\"stroke:rgb(255, 195, 213);stroke-width:2\" />  </svg></g><rect x=\"9.455803940044104%\" y=\"40\" height=\"20\" width=\"1.2782031646351673%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_4').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_4').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_4').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_4').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_4').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_4').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><rect x=\"9.330940096121948%\" y=\"40\" height=\"20\" width=\"0.12486384392215655%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_9').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_9').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_9').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_9').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_9').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_9').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><rect x=\"10.734007104679272%\" width=\"79.9350510075651%\" y=\"40\" height=\"18\" style=\"fill:rgb(0.0, 138.56128015770727, 250.76166088685727); stroke-width:0; stroke:rgb(0,0,0)\" /><line x1=\"10.734007104679272%\" x2=\"22.272702419870722%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_11\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"16.503354762274995%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_11\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.064</text><svg x=\"10.734007104679272%\" y=\"40\" height=\"20\" width=\"11.53869531519145%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">topped</text>  </svg></svg><line x1=\"22.272702419870722%\" x2=\"32.45007214621241%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_2\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"27.361387283041566%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_2\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.057</text><svg x=\"22.272702419870722%\" y=\"40\" height=\"20\" width=\"10.177369726341691%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">hut</text>  </svg></svg><line x1=\"32.45007214621241%\" x2=\"41.40402982762847%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_1\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"36.92705098692044%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_1\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.05</text><svg x=\"32.45007214621241%\" y=\"40\" height=\"20\" width=\"8.953957681416057%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">pizza</text>  </svg></svg><line x1=\"41.40402982762847%\" x2=\"49.75222299790624%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_6\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"45.578126412767354%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_6\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.047</text><svg x=\"41.40402982762847%\" y=\"40\" height=\"20\" width=\"8.348193170277767%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">pizza</text>  </svg></svg><line x1=\"49.75222299790624%\" x2=\"56.87930811079963%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_10\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"53.315765554352936%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_10\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.04</text><svg x=\"49.75222299790624%\" y=\"40\" height=\"20\" width=\"7.12708511289339%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">pizza</text>  </svg></svg><line x1=\"56.87930811079963%\" x2=\"61.72710613750842%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_5\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"59.30320712415403%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_5\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.027</text><svg x=\"56.87930811079963%\" y=\"40\" height=\"20\" width=\"4.847798026708794%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">new</text>  </svg></svg><line x1=\"61.72710613750842%\" x2=\"66.09514080718947%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_14\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"63.91112347234895%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_14\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.024</text><svg x=\"61.72710613750842%\" y=\"40\" height=\"20\" width=\"4.368034669681045%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">pizza</text>  </svg></svg><line x1=\"66.09514080718947%\" x2=\"70.24514296873636%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_13\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"68.17014188796291%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_13\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.023</text><svg x=\"66.09514080718947%\" y=\"40\" height=\"20\" width=\"4.150002161546894%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">smaller</text>  </svg></svg><line x1=\"70.24514296873636%\" x2=\"74.25358471847808%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_12\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"72.24936384360723%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_12\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.022</text><svg x=\"70.24514296873636%\" y=\"40\" height=\"20\" width=\"4.008441749741721%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">with</text>  </svg></svg><line x1=\"74.25358471847808%\" x2=\"77.87024980574289%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_8\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"76.06191726211048%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_8\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.02</text><svg x=\"74.25358471847808%\" y=\"40\" height=\"20\" width=\"3.6166650872648063%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">'</text>  </svg></svg><line x1=\"77.87024980574289%\" x2=\"81.21232923529467%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_16\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"79.54128952051877%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_16\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.019</text><svg x=\"77.87024980574289%\" y=\"40\" height=\"20\" width=\"3.342079429551788%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\"></text>  </svg></svg><line x1=\"81.21232923529467%\" x2=\"84.34531979317028%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_15\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"82.77882451423247%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_15\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.017</text><svg x=\"81.21232923529467%\" y=\"40\" height=\"20\" width=\"3.132990557875601%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">s</text>  </svg></svg><line x1=\"84.34531979317028%\" x2=\"87.0647806289094%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_7\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"85.70505021103983%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_7\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.015</text><svg x=\"84.34531979317028%\" y=\"40\" height=\"20\" width=\"2.7194608357391274%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">lover</text>  </svg></svg><line x1=\"87.0647806289094%\" x2=\"89.63104898596355%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_0\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"88.34791480743647%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_0\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.014</text><svg x=\"87.0647806289094%\" y=\"40\" height=\"20\" width=\"2.566268357054142%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\"></text>  </svg></svg><line x1=\"89.63104898596355%\" x2=\"90.66905811224436%\" y1=\"60\" y2=\"60\" id=\"_fb_gffxajtqekncpkywuikj_ind_3\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2; opacity: 0\"/><text x=\"90.15005354910394%\" y=\"71\" font-size=\"12px\" fill=\"rgb(0.0, 138.56128015770727, 250.76166088685727)\" id=\"_fs_gffxajtqekncpkywuikj_ind_3\" style=\"opacity: 0\" dominant-baseline=\"middle\" text-anchor=\"middle\">-0.006</text><svg x=\"89.63104898596355%\" y=\"40\" height=\"20\" width=\"1.0380091262808122%\">  <svg x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">    <text x=\"50%\" y=\"9\" font-size=\"12px\" fill=\"rgb(255,255,255)\" dominant-baseline=\"middle\" text-anchor=\"middle\">'</text>  </svg></svg><g transform=\"translate(-8,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-8,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-10,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-12,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-14,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(2,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(0,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-2,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><g transform=\"translate(-4,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(0.0, 138.56128015770727, 250.76166088685727);stroke-width:2\" />  </svg></g><rect transform=\"translate(0,0)\" x=\"10.734007104679272%\" y=\"40\" width=\"8\" height=\"18\" style=\"fill:rgb(0.0, 138.56128015770727, 250.76166088685727)\"/><g transform=\"translate(-6.0,0)\">  <svg x=\"90.66905811224436%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25 L 20 25 L 20 -9\" fill=\"#ffffff\" style=\"stroke:rgb(255,255,255);stroke-width:2\" />  </svg></g><g transform=\"translate(-6.0,0)\">  <svg x=\"22.272702419870722%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"10.734007104679272%\" y=\"40\" height=\"20\" width=\"11.53869531519145%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_11').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_11').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_11').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_11').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_11').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_11').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"32.45007214621241%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"22.272702419870722%\" y=\"40\" height=\"20\" width=\"10.177369726341691%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_2').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_2').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_2').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_2').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_2').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_2').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"41.40402982762847%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"32.45007214621241%\" y=\"40\" height=\"20\" width=\"8.953957681416057%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_1').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_1').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_1').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_1').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_1').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_1').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"49.75222299790624%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"41.40402982762847%\" y=\"40\" height=\"20\" width=\"8.348193170277767%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_6').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_6').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_6').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_6').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_6').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_6').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"56.87930811079963%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"49.75222299790624%\" y=\"40\" height=\"20\" width=\"7.12708511289339%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_10').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_10').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_10').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_10').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_10').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_10').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"61.72710613750842%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"56.87930811079963%\" y=\"40\" height=\"20\" width=\"4.847798026708794%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_5').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_5').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_5').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_5').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_5').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_5').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"66.09514080718947%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"61.72710613750842%\" y=\"40\" height=\"20\" width=\"4.368034669681045%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_14').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_14').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_14').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_14').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_14').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_14').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"70.24514296873636%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"66.09514080718947%\" y=\"40\" height=\"20\" width=\"4.150002161546894%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_13').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_13').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_13').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_13').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_13').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_13').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"74.25358471847808%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"70.24514296873636%\" y=\"40\" height=\"20\" width=\"4.008441749741721%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_12').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_12').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_12').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_12').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_12').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_12').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"77.87024980574289%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"74.25358471847808%\" y=\"40\" height=\"20\" width=\"3.6166650872648063%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_8').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_8').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_8').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_8').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_8').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_8').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"81.21232923529467%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"77.87024980574289%\" y=\"40\" height=\"20\" width=\"3.342079429551788%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_16').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_16').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_16').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_16').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_16').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_16').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"84.34531979317028%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"81.21232923529467%\" y=\"40\" height=\"20\" width=\"3.132990557875601%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_15').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_15').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_15').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_15').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_15').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_15').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"87.0647806289094%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"84.34531979317028%\" y=\"40\" height=\"20\" width=\"2.7194608357391274%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_7').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_7').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_7').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_7').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_7').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_7').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><g transform=\"translate(-6.0,0)\">  <svg x=\"89.63104898596355%\" y=\"40\" height=\"18\" overflow=\"visible\" width=\"30\">    <path d=\"M 8 -9 l -6 18 L 8 25\" fill=\"none\" style=\"stroke:rgb(208, 230, 250);stroke-width:2\" />  </svg></g><rect x=\"87.0647806289094%\" y=\"40\" height=\"20\" width=\"2.566268357054142%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_0').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_0').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_0').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_0').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_0').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_0').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /><rect x=\"89.63104898596355%\" y=\"40\" height=\"20\" width=\"1.0380091262808122%\"      onmouseover=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_3').style.textDecoration = 'underline';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_3').style.opacity = 1;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_3').style.opacity = 1;\"      onmouseout=\"document.getElementById('_tp_gffxajtqekncpkywuikj_ind_3').style.textDecoration = 'none';document.getElementById('_fs_gffxajtqekncpkywuikj_ind_3').style.opacity = 0;document.getElementById('_fb_gffxajtqekncpkywuikj_ind_3').style.opacity = 0;\" style=\"fill:rgb(0,0,0,0)\" /></svg><div align='center'><div style=\"color: rgb(120,120,120); font-size: 12px; margin-top: -15px;\">inputs</div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.014</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_0'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.21960784313725487); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_0').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_0').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_0').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_0').style.opacity = 0;\"\n","        ></div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.05</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_1'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.7714002772826302); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_1').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_1').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_1').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_1').style.opacity = 0;\"\n","        >pizza </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.057</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_2'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.8738760150524857); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_2').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_2').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_2').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_2').style.opacity = 0;\"\n","        >hut</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.006</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_3'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.08560110913052085); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_3').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_3').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_3').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_3').style.opacity = 0;\"\n","        >'</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>0.007</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_4'\n","            style='display: inline; background: rgba(255.0, 13.0, 87.0, 0.10924935630817992); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_4').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_4').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_4').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_4').style.opacity = 0;\"\n","        >s </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.027</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_5'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.41667656961774613); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_5').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_5').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_5').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_5').style.opacity = 0;\"\n","        >new </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.047</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_6'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.7162210338680927); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_6').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_6').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_6').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_6').style.opacity = 0;\"\n","        >pizza </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.015</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_7'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.22749059219647463); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_7').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_7').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_7').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_7').style.opacity = 0;\"\n","        >lover</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.02</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_8'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.30631808278867095); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_8').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_8').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_8').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_8').style.opacity = 0;\"\n","        >'</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>0.001</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_9'\n","            style='display: inline; background: rgba(255.0, 13.0, 87.0, 0.00677361853832443); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_9').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_9').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_9').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_9').style.opacity = 0;\"\n","        >s </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.04</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_10'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.6137452960982374); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_10').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_10').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_10').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_10').style.opacity = 0;\"\n","        >pizza </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.064</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_11'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.9921172509407804); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_11').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_11').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_11').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_11').style.opacity = 0;\"\n","        >topped </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.022</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_12'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.34573182808476927); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_12').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_12').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_12').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_12').style.opacity = 0;\"\n","        >with </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.023</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_13'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.35361457714398903); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_13').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_13').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_13').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_13').style.opacity = 0;\"\n","        >smaller </div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.024</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_14'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.36938007526242816); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_14').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_14').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_14').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_14').style.opacity = 0;\"\n","        >pizza</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.017</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_15'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.2669043374925727); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_15').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_15').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_15').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_15').style.opacity = 0;\"\n","        >s</div></div><div style='display: inline; text-align: center;'\n","    ><div style='display: none; color: #999; padding-top: 0px; font-size: 12px;'>-0.019</div\n","        ><div id='_tp_gffxajtqekncpkywuikj_ind_16'\n","            style='display: inline; background: rgba(30.0, 136.0, 229.0, 0.282669835611012); border-radius: 3px; padding: 0px'\n","            onclick=\"\n","            if (this.previousSibling.style.display == 'none') {\n","                this.previousSibling.style.display = 'block';\n","                this.parentNode.style.display = 'inline-block';\n","            } else {\n","                this.previousSibling.style.display = 'none';\n","                this.parentNode.style.display = 'inline';\n","            }\"\n","            onmouseover=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_16').style.opacity = 1; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_16').style.opacity = 1;\"\n","            onmouseout=\"document.getElementById('_fb_gffxajtqekncpkywuikj_ind_16').style.opacity = 0; document.getElementById('_fs_gffxajtqekncpkywuikj_ind_16').style.opacity = 0;\"\n","        ></div></div></div>"]},"metadata":{}}]},{"cell_type":"code","source":["x = test_sents[0]\n","tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=500, truncation=True) for v in x]).cuda()\n","outputs = model2(tv)[0].detach().cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"f66v31c2UV4r","executionInfo":{"status":"error","timestamp":1670815698492,"user_tz":-60,"elapsed":2097,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"523589dc-1d1b-486d-b2b3-9b3d1c3b5e95"},"id":"f66v31c2UV4r","execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-fec6959ef3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasLtMatmul( ltHandle, computeDesc.descriptor(), &alpha_val, mat1_ptr, Adesc.descriptor(), mat2_ptr, Bdesc.descriptor(), &beta_val, result_ptr, Cdesc.descriptor(), result_ptr, Cdesc.descriptor(), &heuristicResult.algo, workspace.data_ptr(), workspaceSize, at::cuda::getCurrentCUDAStream())`"]}]},{"cell_type":"code","source":["!pip install numba\n","from numba import cuda\n","device = cuda.get_current_device() \n","device.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLeMqeVVXFZS","executionInfo":{"status":"ok","timestamp":1670815581444,"user_tz":-60,"elapsed":8393,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"7efc7def-5f58-474f-ac30-1177b7e6e1f4"},"id":"BLeMqeVVXFZS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (0.56.4)\n","Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.8/dist-packages (from numba) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba) (4.13.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba) (3.11.0)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CJ2SphT2XmJe"},"id":"CJ2SphT2XmJe","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# New day, new failure"],"metadata":{"id":"TGdDfQRCPCj9"},"id":"TGdDfQRCPCj9"},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"CL_Ox60vPK6C"},"id":"CL_Ox60vPK6C","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"PBpg3B7MRLzG","executionInfo":{"status":"error","timestamp":1670847448033,"user_tz":-60,"elapsed":403,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"04631442-06d6-40c6-d57e-530f2a6bed98"},"id":"PBpg3B7MRLzG","execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-869434a7999f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# For every sentence...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# `encode_plus` will:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#   (1) Tokenize the sentence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322,"referenced_widgets":["ea27d2fc9c264b7c8024bf5c5db5d64e","891e965e27c348ca967fc3d0552dda9f","dc4bddbb749e4d06bc73f3a309514c95","bad3ff0018614dc3925d75044f2266e0","84b8bbcf7739475aa0a354d4e02b14b5","5965adc78b264832bf236f6bd501b7f3","7596566420cd4c929483a2ea997d0a1c","d9239af132fa4f51b9eecd8dde65e521","fe0ecc17a300461aa46f88df9c16853c","6711d0f141e14b94a12074e463d3b8ed","9f49a1317fe2488b93996756f272a683","cf6ca9531f8e40c499cda31e8d8a59de","270aeac4abbf4b9b95c6a4a64dccc988","ab8d15c1e1a04a5191a2546fe67f3d21","6e893b4aeef14c709907500922254233","74aca6f1ee894c268751821caf4878d1","67018def9a4543949b3bb9ad40372c96","b2c0e8538dad466abb0d8e22cfd1268f","f3cd2352d3cf4d1691e1d57fd4a19125","715361c9aa384083ad2ac1da52cd31bd","219ef39b957e4755a4d3419bb4c1736c","9f997a7c7f0b406cb714e65455518a4a"]},"id":"Jhk9_XrLP7_I","executionInfo":{"status":"error","timestamp":1670847434708,"user_tz":-60,"elapsed":6928,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"a9042437-1506-4595-c69b-236c4e9cbd4e"},"id":"Jhk9_XrLP7_I","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea27d2fc9c264b7c8024bf5c5db5d64e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6ca9531f8e40c499cda31e8d8a59de"}},"metadata":{}},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-67d0df23cbb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Combine the training inputs into a TensorDataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create a 90-10 train-validation split.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"]}]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"Bngzq6OrRHZ1"},"id":"Bngzq6OrRHZ1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_json(\"./Sarcasm_Headlines_Dataset_v2.json\",lines=True)\n"],"metadata":{"id":"8ifS2Vx3Px7p","executionInfo":{"status":"ok","timestamp":1670847160829,"user_tz":-60,"elapsed":3,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"8ifS2Vx3Px7p","execution_count":12,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split"],"metadata":{"id":"o1K2E6a9P-p8","executionInfo":{"status":"ok","timestamp":1670847145126,"user_tz":-60,"elapsed":633,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"o1K2E6a9P-p8","execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"],"metadata":{"id":"Rt8zf0_GQCPG","executionInfo":{"status":"ok","timestamp":1670847168405,"user_tz":-60,"elapsed":403,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"Rt8zf0_GQCPG","execution_count":13,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"9gZO4byCPsUh","executionInfo":{"status":"ok","timestamp":1670847172269,"user_tz":-60,"elapsed":445,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"9gZO4byCPsUh","execution_count":14,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"YgrmW3L0QlCr","executionInfo":{"status":"ok","timestamp":1670847295768,"user_tz":-60,"elapsed":440,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"YgrmW3L0QlCr","execution_count":20,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"id":"KvE5Jb13PD5D"},"id":"KvE5Jb13PD5D","execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4p404WOPHUv","executionInfo":{"status":"ok","timestamp":1670846980268,"user_tz":-60,"elapsed":20,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"e81ce8d0-929f-4208-aa97-4fe0ec6944fe"},"id":"V4p404WOPHUv","execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"metadata":{"id":"vC1ErYywPVlV","executionInfo":{"status":"ok","timestamp":1670847177851,"user_tz":-60,"elapsed":3,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"vC1ErYywPVlV","execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"elnwu3OzPe7c","executionInfo":{"status":"ok","timestamp":1670847195421,"user_tz":-60,"elapsed":3,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}}},"id":"elnwu3OzPe7c","execution_count":17,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","import torch\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"id":"IHtnEzsdPhrJ","executionInfo":{"status":"error","timestamp":1670847300827,"user_tz":-60,"elapsed":21,"user":{"displayName":"Yusuf Ismail","userId":"13787448978308479981"}},"outputId":"0c54a55f-6504-4475-87d6-fc09bdfc727f"},"id":"IHtnEzsdPhrJ","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 9454","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4e58ca23071e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# For each batch of training data...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Progress update every 40 batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 9454"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gL7dXLZeQR_4"},"id":"gL7dXLZeQR_4","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":["85e473f3"]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"7f0d01b0ff3d47bcbfb3f989c560ec2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f08a8b80d9074fa5b92df28b6b1378c5","IPY_MODEL_c0083c855d4a4e64878ff403c752370c","IPY_MODEL_521e61a6e70549c0b5c2158dac6abe2a"],"layout":"IPY_MODEL_bc3be1322fd24c6a8b9cb582def7721b"}},"f08a8b80d9074fa5b92df28b6b1378c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01eb5c6469874f9babfd8ef7ab3091be","placeholder":"​","style":"IPY_MODEL_c66141cb788f4a928422302431856c35","value":"Downloading: 100%"}},"c0083c855d4a4e64878ff403c752370c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8470d042ec2d429d9ef52e6ea07db222","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_084f849ae862426099fcfdcd882c1e23","value":231508}},"521e61a6e70549c0b5c2158dac6abe2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cae8036ac1245b48adfa2624b72de34","placeholder":"​","style":"IPY_MODEL_4efc691372cd44c4b9e1cd7a46842723","value":" 232k/232k [00:00&lt;00:00, 2.57MB/s]"}},"bc3be1322fd24c6a8b9cb582def7721b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01eb5c6469874f9babfd8ef7ab3091be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66141cb788f4a928422302431856c35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8470d042ec2d429d9ef52e6ea07db222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"084f849ae862426099fcfdcd882c1e23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cae8036ac1245b48adfa2624b72de34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4efc691372cd44c4b9e1cd7a46842723":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"521ffa23dea940808244fab46a24c6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_488e4fd5da2648868989b3d7a0d26085","IPY_MODEL_e5320a0fd40c4544bdcf218915be922a","IPY_MODEL_8fcd4b61c31c4000879fccf2eb353a5d"],"layout":"IPY_MODEL_5eafff19aae44e0cabaf86820a09d247"}},"488e4fd5da2648868989b3d7a0d26085":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cc61425a81843928137581fb48ab731","placeholder":"​","style":"IPY_MODEL_77383d5d3e9b4e5ea3b12df059b7b0d5","value":"Downloading: 100%"}},"e5320a0fd40c4544bdcf218915be922a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_557da984cab744e6873bc4d0610927e8","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01baf34aaaa7428489f5d1fa2ab7b2c7","value":28}},"8fcd4b61c31c4000879fccf2eb353a5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_754a88b2d4d94d4eae5f19673a3519c4","placeholder":"​","style":"IPY_MODEL_6aaaea093c214dbc99bc8ace61b4a5f1","value":" 28.0/28.0 [00:00&lt;00:00, 370B/s]"}},"5eafff19aae44e0cabaf86820a09d247":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc61425a81843928137581fb48ab731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77383d5d3e9b4e5ea3b12df059b7b0d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"557da984cab744e6873bc4d0610927e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01baf34aaaa7428489f5d1fa2ab7b2c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"754a88b2d4d94d4eae5f19673a3519c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aaaea093c214dbc99bc8ace61b4a5f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3843ba28a494e2ab47abbdae600fc09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d143e2a966ab4ac089d5f62e7f0d6500","IPY_MODEL_cd6d0e987845400798c4a2baa04ad535","IPY_MODEL_52e1adabc57b433db4feabc466046c8b"],"layout":"IPY_MODEL_74c6ce947c1e474e8e184a1e25a16f69"}},"d143e2a966ab4ac089d5f62e7f0d6500":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_077b05b03d0b4f99b1dd44f8cd114cd7","placeholder":"​","style":"IPY_MODEL_a655b3ebd6374483b62b3e19e702c436","value":"Downloading: 100%"}},"cd6d0e987845400798c4a2baa04ad535":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13acf7dc59f44ec3b1f4697d4c27c0a3","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aee2687f6a2496ab44c39998133ad87","value":570}},"52e1adabc57b433db4feabc466046c8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48fc101ce6fc4ac2b4c5a2b29c91f9e3","placeholder":"​","style":"IPY_MODEL_657a3e5bd7154fbcbeedacad2b33e3fc","value":" 570/570 [00:00&lt;00:00, 8.45kB/s]"}},"74c6ce947c1e474e8e184a1e25a16f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"077b05b03d0b4f99b1dd44f8cd114cd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a655b3ebd6374483b62b3e19e702c436":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13acf7dc59f44ec3b1f4697d4c27c0a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aee2687f6a2496ab44c39998133ad87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48fc101ce6fc4ac2b4c5a2b29c91f9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"657a3e5bd7154fbcbeedacad2b33e3fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd2947fdc6814351808d95c0cea6c757":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_650c87a5bbe84e1593fae5b4d4f6413e","IPY_MODEL_cd02af6a01764713b75873369667954a","IPY_MODEL_d73b59eae53f416ea30394a6c2d7e2b4"],"layout":"IPY_MODEL_0337bd2fec24404aba8f4319248052aa"}},"650c87a5bbe84e1593fae5b4d4f6413e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c0178fe65449a5ad705cf250c89bf0","placeholder":"​","style":"IPY_MODEL_66697ae1026b4161a9ff182c76d4567c","value":"Downloading: 100%"}},"cd02af6a01764713b75873369667954a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b848a5186df04d6ea605d38835ddf285","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffc6725f07364079be53fa2b0cc27d80","value":536063208}},"d73b59eae53f416ea30394a6c2d7e2b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_263e6fcf9a1340a1868e399df3fb2189","placeholder":"​","style":"IPY_MODEL_224f1386a4a1404ea4f5dba62cf90b63","value":" 536M/536M [00:09&lt;00:00, 73.8MB/s]"}},"0337bd2fec24404aba8f4319248052aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25c0178fe65449a5ad705cf250c89bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66697ae1026b4161a9ff182c76d4567c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b848a5186df04d6ea605d38835ddf285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffc6725f07364079be53fa2b0cc27d80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"263e6fcf9a1340a1868e399df3fb2189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"224f1386a4a1404ea4f5dba62cf90b63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea27d2fc9c264b7c8024bf5c5db5d64e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_891e965e27c348ca967fc3d0552dda9f","IPY_MODEL_dc4bddbb749e4d06bc73f3a309514c95","IPY_MODEL_bad3ff0018614dc3925d75044f2266e0"],"layout":"IPY_MODEL_84b8bbcf7739475aa0a354d4e02b14b5"}},"891e965e27c348ca967fc3d0552dda9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5965adc78b264832bf236f6bd501b7f3","placeholder":"​","style":"IPY_MODEL_7596566420cd4c929483a2ea997d0a1c","value":"Downloading: 100%"}},"dc4bddbb749e4d06bc73f3a309514c95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9239af132fa4f51b9eecd8dde65e521","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe0ecc17a300461aa46f88df9c16853c","value":231508}},"bad3ff0018614dc3925d75044f2266e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6711d0f141e14b94a12074e463d3b8ed","placeholder":"​","style":"IPY_MODEL_9f49a1317fe2488b93996756f272a683","value":" 232k/232k [00:00&lt;00:00, 262kB/s]"}},"84b8bbcf7739475aa0a354d4e02b14b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5965adc78b264832bf236f6bd501b7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7596566420cd4c929483a2ea997d0a1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9239af132fa4f51b9eecd8dde65e521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe0ecc17a300461aa46f88df9c16853c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6711d0f141e14b94a12074e463d3b8ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f49a1317fe2488b93996756f272a683":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf6ca9531f8e40c499cda31e8d8a59de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_270aeac4abbf4b9b95c6a4a64dccc988","IPY_MODEL_ab8d15c1e1a04a5191a2546fe67f3d21","IPY_MODEL_6e893b4aeef14c709907500922254233"],"layout":"IPY_MODEL_74aca6f1ee894c268751821caf4878d1"}},"270aeac4abbf4b9b95c6a4a64dccc988":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67018def9a4543949b3bb9ad40372c96","placeholder":"​","style":"IPY_MODEL_b2c0e8538dad466abb0d8e22cfd1268f","value":"Downloading: 100%"}},"ab8d15c1e1a04a5191a2546fe67f3d21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3cd2352d3cf4d1691e1d57fd4a19125","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_715361c9aa384083ad2ac1da52cd31bd","value":28}},"6e893b4aeef14c709907500922254233":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_219ef39b957e4755a4d3419bb4c1736c","placeholder":"​","style":"IPY_MODEL_9f997a7c7f0b406cb714e65455518a4a","value":" 28.0/28.0 [00:00&lt;00:00, 261B/s]"}},"74aca6f1ee894c268751821caf4878d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67018def9a4543949b3bb9ad40372c96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c0e8538dad466abb0d8e22cfd1268f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3cd2352d3cf4d1691e1d57fd4a19125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"715361c9aa384083ad2ac1da52cd31bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"219ef39b957e4755a4d3419bb4c1736c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f997a7c7f0b406cb714e65455518a4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}